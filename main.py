import os
import json
import requests
import google.generativeai as genai
from feedgen.feed import FeedGenerator
from datetime import datetime, timezone

# --- è¨­å®šé …ç›®ï¼šã“ã“ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¦ãã ã•ã„ ---

# Tavily APIã§æ¤œç´¢ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
SEARCH_QUERIES = [
    "å¥‘ç´„æ›¸ æ³•æ”¹æ­£ ãƒ‹ãƒ¥ãƒ¼ã‚¹",
    "é›»å­å¥‘ç´„ æœ€æ–°å‹•å‘",
    "ä¸‹è«‹æ³• ãƒ‹ãƒ¥ãƒ¼ã‚¹ 2024",
    "å€‹äººæƒ…å ±ä¿è­·æ³• è¦ç´„æ”¹å®š",
    "ãƒªãƒ¼ã‚¬ãƒ«ãƒ†ãƒƒã‚¯ å¥‘ç´„æ¥­å‹™"
]

# RSSãƒ•ã‚£ãƒ¼ãƒ‰ã®åŸºæœ¬æƒ…å ±
RSS_FEED_LINK = "https://github.com/momocatmeow-contract-news-rss/momocatmeow-contract-news-rss" 
RSS_FEED_TITLE = "AIå³é¸ï¼å¥‘ç´„æ›¸é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹"
RSS_FEED_DESCRIPTION = "AIãŒWebã‹ã‚‰è‡ªå‹•åé›†ã—ãŸå¥‘ç´„é–¢é€£ã®æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã§ã™ã€‚ï¼ˆæœ¬æ–‡è¡¨ç¤ºï¼‰"
RSS_FILE_NAME = "feed.xml"

# --- Gemini APIã¸ã®æŒ‡ç¤ºï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ ---
GEMINI_PROMPT = """
ã‚ãªãŸã¯ã€æ—¥æœ¬ä¼æ¥­ã®æ³•å‹™æ‹…å½“è€…ã‚„å¼è­·å£«å‘ã‘ã«æƒ…å ±æä¾›ã‚’è¡Œã†ã€éå¸¸ã«å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®Webè¨˜äº‹ã®å†…å®¹ã‚’åˆ†æã—ã€å¥‘ç´„å®Ÿå‹™ã€æ³•æ”¹æ­£ã€ã¾ãŸã¯é–¢é€£ã™ã‚‹ãƒªãƒ¼ã‚¬ãƒ«ãƒ†ãƒƒã‚¯ã®å‹•å‘ã«ã¤ã„ã¦ã€å°‚é–€å®¶ã«ã¨ã£ã¦ä¾¡å€¤ã®ã‚ã‚‹é‡è¦ãªæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚

åˆ¤æ–­åŸºæº–ï¼š
- å˜ãªã‚‹è£½å“ç´¹ä»‹ã‚„ã‚¤ãƒ™ãƒ³ãƒˆå‘ŠçŸ¥ã§ã¯ãªãã€å®Ÿå‹™ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹å…·ä½“çš„ãªæƒ…å ±ï¼ˆæ³•æ”¹æ­£ã€åˆ¤ä¾‹ã€æ–°æŠ€è¡“ã®æ³•çš„è«–ç‚¹ãªã©ï¼‰ã‚’å«ã‚“ã§ã„ã‚‹ã‹ã€‚
- å°‚é–€å®¶ãŒç›®ã‚’é€šã™ã¹ãã€ç¤ºå”†ã«å¯Œã‚“ã å†…å®¹ã‹ã€‚

è¨˜äº‹ã‚’åˆ†æã—ãŸçµæœã€é‡è¦ã ã¨åˆ¤æ–­ã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§çµæœã‚’å¿…ãšå‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
{{
  "is_important": true,
  "title": "ï¼ˆè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç°¡æ½”ã«è¦ç´„ï¼‰",
  "category": "ï¼ˆã€Œæ³•æ”¹æ­£ã€ã€Œé›»å­å¥‘ç´„ã€ã€Œåˆ¤ä¾‹ã€ã€ŒM&Aã€ã€ŒçŸ¥è²¡ã€ãªã©ã€æœ€ã‚‚é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªã‚’ä¸€ã¤ï¼‰"
}}

é‡è¦ã§ã¯ãªã„ã€ã¾ãŸã¯åˆ†æã§ããªã„ã¨åˆ¤æ–­ã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
{{
  "is_important": false
}}

--- è¨˜äº‹æœ¬æ–‡ ---
{article_text}
"""

# --- ãƒ¡ã‚¤ãƒ³ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆã“ã“ã‹ã‚‰ä¸‹ã¯é€šå¸¸å¤‰æ›´ä¸è¦ã§ã™ï¼‰ ---

# APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€
try:
    genai.configure(api_key=os.environ["GOOGLE_GEMINI_API_KEY"])
    tavily_api_key = os.environ["TAVILY_API_KEY"]
except KeyError:
    print("ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("GitHub Actionsã®Secretsã« GOOGLE_GEMINI_API_KEY ã¨ TAVILY_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    exit(1)


def search_with_tavily(query: str, max_results: int = 5) -> list:
    """Tavily APIã‚’ä½¿ã£ã¦Webæ¤œç´¢ã—ã€URLã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    print(f"ğŸ” æ¤œç´¢ä¸­: '{query}'")
    try:
        response = requests.post(
            "https://api.tavily.com/search",
            json={
                "api_key": tavily_api_key,
                "query": query,
                "search_depth": "basic",
                "include_images": False,
                "max_results": max_results
            }
        )
        response.raise_for_status()
        results = response.json().get("results", [])
        urls = [res.get("url") for res in results if res.get("url")]
        print(f"âœ… {len(urls)}ä»¶ã®URLãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
        return urls
    except requests.exceptions.RequestException as e:
        print(f"âŒ Tavily APIã§ã®æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def get_article_content_from_jina(url: str) -> str | None:
    """Jina AI Readerã‚’ä½¿ã£ã¦URLã‹ã‚‰è¨˜äº‹æœ¬æ–‡ã‚’Markdownå½¢å¼ã§æŠ½å‡ºã™ã‚‹"""
    print(f"ğŸ“„ è¨˜äº‹å–å¾—ä¸­: {url}")
    jina_reader_url = f"https://r.jina.ai/{url}"
    try:
        response = requests.get(jina_reader_url, timeout=60)
        response.raise_for_status()
        content = response.text
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if line.strip().startswith('#'):
                return '\n'.join(lines[i:])
        return content
    except requests.exceptions.RequestException as e:
        print(f"âŒ Jina Readerã§ã®è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def analyze_with_gemini(article_text: str) -> dict | None: # é–¢æ•°åã‚’å®Ÿæ…‹ã«åˆã‚ã›ã¦å¤‰æ›´
    """Gemini APIã‚’ä½¿ã£ã¦è¨˜äº‹ã‚’åˆ†æã—ã€é‡è¦ã‹ã©ã†ã‹ã‚’JSONå½¢å¼ã§è¿”ã™"""
    print("ğŸ§  Geminiã«ã‚ˆã‚‹åˆ†æä¸­...")
    model = genai.GenerativeModel('gemini-1.5-flash')
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ "summary" ã®ç”ŸæˆæŒ‡ç¤ºã‚’å‰Šé™¤
    prompt = GEMINI_PROMPT.format(article_text=article_text) 
    try:
        response = model.generate_content(prompt)
        cleaned_text = response.text.strip().replace("```json", "").replace("```", "").strip()
        result = json.loads(cleaned_text)
        print(f"âœ¨ Geminiã®åˆ†æå®Œäº†: é‡è¦ã‹ï¼Ÿ -> {result.get('is_important')}")
        return result
    except Exception as e:
        print(f"âŒ Gemini APIã§ã®åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        try:
            print(f"å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ: {response.text[:200]}") # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¸€éƒ¨è¡¨ç¤º
        except NameError:
            pass
        return None


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹"""
    print("ğŸš€ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹")

    all_urls = set()
    for query in SEARCH_QUERIES:
        urls = search_with_tavily(query)
        for url in urls:
            all_urls.add(url)

    print(f"\nåˆè¨ˆ {len(all_urls)}ä»¶ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªURLã‚’å‡¦ç†ã—ã¾ã™ã€‚")
    
    important_articles = []
    for url in all_urls:
        article_text = get_article_content_from_jina(url)
        if article_text:
            # ### å¤‰æ›´ç‚¹ 1: Geminiã«ã¯åˆ†æã ã‘ã‚’ã•ã›ã€æœ¬æ–‡ã¯åˆ¥ã«ä¿æŒã™ã‚‹ ###
            analysis_result = analyze_with_gemini(article_text)
            
            # GeminiãŒé‡è¦ã¨åˆ¤æ–­ã—ãŸå ´åˆ
            if analysis_result and analysis_result.get("is_important"):
                # è¨˜äº‹ã®æƒ…å ±ã‚’ä¸€ã¤ã®è¾æ›¸ã«ã¾ã¨ã‚ã‚‹
                article_data = {
                    'title': analysis_result.get("title", "No Title"),
                    'category': analysis_result.get("category", "N/A"),
                    'link': url,
                    'full_text': article_text # <- ã“ã“ã§è¨˜äº‹æœ¬æ–‡ã‚’ä¿æŒã™ã‚‹
                }
                important_articles.append(article_data)

        print("-" * 20)

    if not important_articles:
        print("ğŸ˜­ AIãŒé‡è¦ã¨åˆ¤æ–­ã—ãŸè¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # è¨˜äº‹ãŒãªã„å ´åˆã§ã‚‚ç©ºã®ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ä¸Šæ›¸ãã™ã‚‹
        fg = FeedGenerator()
        fg.title(RSS_FEED_TITLE)
        fg.link(href=RSS_FEED_LINK, rel='alternate')
        fg.description(RSS_FEED_DESCRIPTION)
        fg.rss_file(RSS_FILE_NAME, pretty=True)
        print("ğŸ“ ç©ºã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        return

    print(f"\nğŸ‰ {len(important_articles)}ä»¶ã®é‡è¦è¨˜äº‹ã‚’RSSãƒ•ã‚£ãƒ¼ãƒ‰ã¨ã—ã¦ç”Ÿæˆã—ã¾ã™ã€‚")

    # RSSãƒ•ã‚£ãƒ¼ãƒ‰ã®ç”Ÿæˆ
    fg = FeedGenerator()
    fg.title(RSS_FEED_TITLE)
    fg.link(href=RSS_FEED_LINK, rel='alternate')
    fg.description(RSS_FEED_DESCRIPTION)

    # ### å¤‰æ›´ç‚¹ 2: descriptionã«è¦ç´„(summary)ã®ä»£ã‚ã‚Šã«è¨˜äº‹æœ¬æ–‡(full_text)ã‚’å…¥ã‚Œã‚‹ ###
    for article in important_articles:
        fe = fg.add_entry()
        fe.title(article.get("title"))
        fe.link(href=article.get("link"))
        
        category = article.get("category", "N/A")
        full_text_content = article.get("full_text", "è¨˜äº‹æœ¬æ–‡ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # HTMLã¨ã—ã¦descriptionã‚’æ§‹æˆã™ã‚‹
        fe.description(f"<b>ã€ã‚«ãƒ†ã‚´ãƒªã€‘: {category}</b><br/><br/><hr/><br/>{full_text_content.replace('\n', '<br/>')}")

    # RSSãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    fg.rss_file(RSS_FILE_NAME, pretty=True)
    print(f"âœ… RSSãƒ•ã‚¡ã‚¤ãƒ« '{RSS_FILE_NAME}' ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    print("ğŸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†")


if __name__ == "__main__":
    main()
